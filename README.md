# üîç CRISP-T (**CRoss** **I**ndustry **S**tandard **P**rocess for **T**riangulation)

[![Release](https://img.shields.io/github/v/release/dermatologist/crisp-t)](https://img.shields.io/github/v/release/dermatologist/crisp-t)
[![Build status](https://img.shields.io/github/actions/workflow/status/dermatologist/crisp-t/pytest.yml?branch=develop)](https://github.com/dermatologist/crisp-t/actions/workflows/pytest.yml?query=branch%3Adevelop)
[![codecov](https://codecov.io/gh/dermatologist/crisp-t/branch/develop/graph/badge.svg)](https://codecov.io/gh/dermatologist/crisp-t)
[![Commit activity](https://img.shields.io/github/commit-activity/m/dermatologist/crisp-t)](https://img.shields.io/github/commit-activity/m/dermatologist/crisp-t)
[![License](https://img.shields.io/github/license/dermatologist/crisp-t)](https://img.shields.io/github/license/dermatologist/crisp-t)
[![Downloads](https://img.shields.io/pypi/dm/crisp-t)](https://pypi.org/project/crisp-t)
[![Documentation](https://badgen.net/badge/icon/documentation?icon=libraries&label)](https://dermatologist.github.io/crisp-t/)
<!-- gh-dependents-info-used-by-start -->
[![Generated by github-dependents-info](https://img.shields.io/static/v1?label=Used%20by&message=2&color=informational&logo=slickpic)](https://github.com/dermatologist/crisp-t/blob/develop/docs/github-dependents-info.md)<!-- gh-dependents-info-used-by-end -->

Qualitative research involves the collection and analysis of textual data, such as interview transcripts, open-ended survey responses, and field notes. It is often used in social sciences, humanities, and health research to explore complex phenomena and understand human experiences. In addition to textual data, qualitative researchers may also collect quantitative data, such as survey responses or demographic information, to complement their qualitative findings.

Qualitative research is often characterized by its inductive approach, where researchers aim to generate theories or concepts from the data rather than testing pre-existing hypotheses. This process is known as Grounded Theory, which emphasizes the importance of data-driven analysis and theory development.

We are developing a framework that integrates **textual data** (as a list of documents) and **numeric data** (as Pandas DataFrame) into structured classes that retain **metadata** from various analytical processes, such as **topic modeling** and **decision trees**. Researchers, with or without GenAI assistance, can define relationships between textual and numerical datasets based on their chosen **theoretical lens**.  A final analytical phase ensures that proposed relationships actually hold true.

An MCP server exposes all functionality as tools, resources, and prompts, enabling integration with AI assistants and other MCP-compatible clients.

[![crisp-t](https://github.com/dermatologist/crisp-t/blob/develop/notes/arch.drawio.svg)](https://github.com/dermatologist/crisp-t/blob/develop/notes/arch.drawio.svg)

## Installation

```bash
pip install crisp-t
```

For machine learning features:
```bash
pip install crisp-t[ml]
```

## Command Line Scripts

CRISP-T now provides three main command-line scripts:

- `crisp` ‚Äî Main CLI for qualitative triangulation and analysis (see below)
- `crispviz` ‚Äî Visualization CLI for corpus data (word frequencies, topic charts, wordclouds, etc.)
- `crispt` ‚Äî Corpus manipulation CLI (create, edit, query, and manage corpus objects)

All scripts are installed as entry points and can be run directly from the command line after installation.

### crisp (Triangulation CLI)

```bash
crisp [OPTIONS]
```

#### Input/Output Options

- `--inp, -i PATH`: Load an existing corpus from a folder containing `corpus.json` (and optional `corpus_df.csv`)
- `--out, -o PATH`: When saving the corpus, provide a folder path; the CLI writes `corpus.json` (and `corpus_df.csv` if available) into that folder. When saving analysis results (topics, sentiment, etc.), this acts as a base path: files are written with suffixes, e.g., `results_topics.json`.
- `--unstructured, -t TEXT`: Text CSV column(s) to analyze/compare (can be used multiple times)
- `--ignore TEXT`: Comma-separated words to ignore during ingestion (applies to `--source/--sources`)

#### Analysis Options

- `--codedict`: Generate qualitative coding dictionary
- `--topics`: Generate topic model using LDA
- `--assign`: Assign documents to topics
- `--cat`: List categories of entire corpus or individual documents
- `--summary`: Generate extractive text summary
- `--sentiment`: Generate sentiment scores using VADER
- `--sentence`: Generate sentence-level scores when applicable
- `--nlp`: Generate all NLP reports (combines above text analyses)
- `--nnet`, `--cls`, `--knn`, `--kmeans`, `--cart`, `--pca`, `--regression`, `--ml`: Machine learning and clustering options (requires `crisp-t[ml]`)
  - `--regression`: Perform linear or logistic regression (automatically detects binary outcomes for logistic regression)
- `--visualize`: Generate visualizations (word clouds, topic charts, etc.)
- `--num, -n INTEGER`: Number parameter (clusters, topics, epochs, etc.) - default: 3
- `--rec, -r INTEGER`: Record parameter (top N results, recommendations) - default: 3
- `--filters, -f TEXT`: Filters to apply as `key=value` (can be used multiple times); keeps only documents where `document.metadata[key] == value`. Invalid formats raise an error.
- `--verbose, -v`: Print verbose messages for debugging

#### Data Sources

- `--source, -s PATH|URL`: Read source data from a directory (reads .txt and .pdf) or from a URL
- `--sources PATH|URL`: Provide multiple sources; can be used multiple times

### crispviz (Visualization CLI)

```bash
crispviz [OPTIONS]
```

- `--inp, --source, --sources`: Input corpus or sources
- `--out`: Output directory for PNG images
- Visualization flags: `--freq`, `--by-topic`, `--wordcloud`, `--top-terms`, `--corr-heatmap`
- Optional params: `--bins`, `--top-n`, `--columns`

### crispt (Corpus Manipulation CLI)

```bash
crispt [OPTIONS]
```

- `--id`, `--name`, `--description`: Corpus metadata
- `--doc`: Add document as `id|name|text` or `id|text` (repeatable)
- `--remove-doc`: Remove document by ID (repeatable)
- `--meta`: Add/update corpus metadata as `key=value` (repeatable)
- `--add-rel`: Add relationship as `first|second|relation` (repeatable)
- `--clear-rel`: Clear all relationships
- `--out`: Save corpus to folder/file as `corpus.json`
- `--inp`: Load corpus from folder/file containing `corpus.json`
- Query options:
	- `--df-cols`: Print DataFrame column names
	- `--df-row-count`: Print DataFrame row count
	- `--df-row INDEX`: Print DataFrame row by index
	- `--doc-ids`: Print all document IDs
	- `--doc-id ID`: Print document by ID
	- `--relationships`: Print all relationships
	- `--relationships-for-keyword KEYWORD`: Print relationships involving a keyword

### Example Usage

#### Corpus Creation and Manipulation
```bash
# Create a new corpus and add documents
crispt --id mycorpus --name "My Corpus" --doc "d1|Doc 1|Text" --doc "d2|Doc 2|More text" --out ./corpus_folder

# Load and query corpus
crispt --inp ./corpus_folder --doc-ids --relationships

# Add relationships and query by keyword
crispt --inp ./corpus_folder --add-rel "text:foo|num:bar|correlates" --relationships-for-keyword foo
```

#### Triangulation and Analysis
```bash
# Load corpus and perform text analysis
crisp --inp ./corpus_folder --codedict --sentiment

# Topic modeling and clustering
crisp --inp ./corpus_folder --topics --assign --num 4 --rec 10
```

#### Visualization
```bash
# Generate word frequency and topic visualizations
crispviz --inp ./corpus_folder --freq --by-topic --out ./viz_out
```

### Output Formats

Results can be saved in multiple formats:
- **JSON**: Default format, preserves all data structures
- **CSV**: For tabular data (DataFrames, topic assignments, etc.)
- **Text**: For readable reports and summaries

When saving analysis outputs via `--out`, files are automatically named with suffixes indicating the analysis type:
- `*_coding_dictionary.json`: Qualitative coding results
- `*_topics.json`: Topic modeling results
- `*_sentiment.json`: Sentiment analysis results
- `*_kmeans.json`: Clustering results
- `*_ml_results.json`: Classification results

When saving the corpus via `--out`, the CLI writes `corpus.json` (and `corpus_df.csv` if present) into the specified folder. If you pass a file path, only its parent directory is used for writing `corpus.json`.

## MCP Server

CRISP-T provides a Model Context Protocol (MCP) server that exposes all functionality as tools, resources, and prompts. This enables integration with AI assistants and other MCP-compatible clients.

### Starting the MCP Server

The MCP server runs via stdio and can be started with:

```bash
crisp-mcp
```

Or using Python directly:

```bash
python -m crisp_t.mcp
```

### Configuring MCP Clients
<p align="center">
  <img src="https://github.com/dermatologist/crisp-t/blob/develop/notes/crisp.gif" />
</p>

#### Claude Desktop

Add to your Claude Desktop configuration file:

**MacOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`
**Windows**: `%APPDATA%\Claude\claude_desktop_config.json`

```json
{
  "mcpServers": {
    "crisp-t": {
      "command": "crisp-mcp"
    }
  }
}
```

#### Using with Other MCP Clients

The server can be used with any MCP-compatible client. Configure your client to run the `crisp-mcp` command via stdio.

### Available Tools

The MCP server provides tools for:

**Corpus Management**
- `load_corpus` - Load corpus from folder or source
- `save_corpus` - Save corpus to folder
- `add_document` - Add new document
- `remove_document` - Remove document by ID
- `get_document` - Get document details
- `list_documents` - List all document IDs
- `add_relationship` - Link text keywords with numeric columns
- `get_relationships` - Get all relationships
- `get_relationships_for_keyword` - Query relationships by keyword

**NLP/Text Analysis**
- `generate_coding_dictionary` - Extract categories, properties, dimensions
- `topic_modeling` - Discover topics using LDA
- `assign_topics` - Assign documents to topics (creates keyword labels)
- `extract_categories` - Extract common concepts
- `generate_summary` - Generate extractive summary
- `sentiment_analysis` - VADER sentiment analysis

**DataFrame/CSV Operations**
- `get_df_columns` - Get DataFrame column names
- `get_df_row_count` - Get number of rows
- `get_df_row` - Get specific row by index

**Machine Learning** (requires `crisp-t[ml]`)
- `kmeans_clustering` - K-Means clustering
- `decision_tree_classification` - Decision tree with feature importance
- `svm_classification` - SVM classification
- `neural_network_classification` - Neural network classification
- `regression_analysis` - Linear/logistic regression with coefficients
- `pca_analysis` - Principal Component Analysis
- `association_rules` - Apriori association rules
- `knn_search` - K-nearest neighbors search

### Resources

The server exposes corpus documents as resources:
- `corpus://document/{id}` - Access document text by ID

### Prompts

- `analysis_workflow` - Complete step-by-step analysis guide based on INSTRUCTIONS.md
- `triangulation_guide` - Guide for triangulating qualitative and quantitative findings

### Example Usage via MCP

1. Load a corpus: `load_corpus` with `inp="/path/to/corpus"`
2. Perform topic modeling: `topic_modeling` with `num_topics=5`
3. Assign documents to topics: `assign_topics` (creates keyword labels for documents)
4. Run regression: `regression_analysis` with `outcome="target_var"` (returns coefficients)
5. Link findings: `add_relationship` with `first="text:healthcare"`, `second="num:satisfaction"`, `relation="correlates"`
6. Save results: `save_corpus` with `out="/path/to/output"`

The workflow enables AI assistants to help conduct comprehensive analyses by combining text analytics, machine learning, and triangulation of qualitative-quantitative findings.

## Example use

A company collects:
- **Textual** feedback from customer support interactions.
- **Numerical** data on customer retention and sales performance.
Using this framework, business analysts can investigate how recurring concerns in feedback correspond to measurable business outcomes.

## Framework Documentation

For detailed information about available functions, metadata handling, and theoretical frameworks, see the [comprehensive user instructions](/notes/INSTRUCTION.md).

## Author

* [Bell Eapen](https://nuchange.ca) ([UIS](https://www.uis.edu/directory/bell-punneliparambil-eapen)) |  [Contact](https://nuchange.ca/contact) | [![Twitter Follow](https://img.shields.io/twitter/follow/beapen?style=social)](https://twitter.com/beapen)


## Citation

Under review.

## Give us a star ‚≠êÔ∏è
If you find this project useful, give us a star. It helps others discover the project.
